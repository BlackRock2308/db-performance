version: '3'
services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - spark_events:/tmp/spark-events
      - /Users/macbookpro/Documents/db-perf-project:/project # Mount project directory
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop-hive.env
    ports:
      - 9870:9870
      - 8020:8020

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    depends_on:
      - namenode
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
      - spark_events:/tmp/spark-events
    env_file:
      - ./hadoop-hive.env
    ports:
      - 9864:9864

  spark-master:
    image: bde2020/spark-master:3.1.2-hadoop3.2
    container_name: spark-master
    depends_on:
      - namenode
    ports:
      - 8080:8080
      - 7077:7077
      - 4040:4040  # Add this line to expose Spark application UI
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - SPARK_MASTER_HOST=0.0.0.0
      - SPARK_LOCAL_DIRS=/tmp
      - SPARK_CONF_DIR=/spark/conf
      - SPARK_WORKER_DIR=/tmp/spark-events
      - SPARK_MASTER_OPTS=-Dspark.deploy.recoveryMode=FILESYSTEM
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=hdfs://namenode:8020/tmp/spark-events
    env_file:
      - ./hadoop-hive.env
    volumes:
      - spark_events:/tmp/spark-events

  spark-worker:
    image: bde2020/spark-worker:3.1.2-hadoop3.2
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - 8081:8081
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_OPTS=-Dspark.worker.dir=/tmp/spark-events
    env_file:
      - ./hadoop-hive.env
    volumes:
      - spark_events:/tmp/spark-events

  spark-history-server:
    image: bde2020/spark-history-server:3.1.2-hadoop3.2
    container_name: spark-history-server
    depends_on:
      - spark-master
    ports:
      - 18080:18081
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=hdfs://namenode:8020/tmp/spark-events
    volumes:
      - spark_events:/tmp/spark-events

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    env_file:
      - ./hadoop-hive.env
    ports:
      - 10000:10000
      - 10002:10002
    volumes:
      - spark_events:/tmp/spark-events

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    depends_on:
      - postgresql
    env_file:
      - ./hadoop-hive.env

  postgresql:
    image: postgres:12
    container_name: postgresql
    environment:
      - POSTGRES_DB=metastore
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - 5432:5432

  hue:
    image: gethue/hue:latest
    container_name: hue
    ports:
      - 8888:8888
    volumes:
      - ./hue-overrides.ini:/usr/share/hue/desktop/conf/hue.ini
    depends_on:
      - postgresql
    environment:
      - DATABASE_HOST=postgresql
      - DATABASE_PORT=5432
      - DATABASE_TYPE=postgresql
      - DATABASE_NAME=metastore
      - DATABASE_USER=hive
      - DATABASE_PASSWORD=hive

volumes:
  hadoop_namenode:
  hadoop_datanode:
  postgres_data:
  spark_events:
